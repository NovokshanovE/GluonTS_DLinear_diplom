step,train_loss,epoch
99,10.164571762084961,0
199,16.587913513183594,1
299,9.152253150939941,2
399,9.069173812866211,3
499,9.153696060180664,4
599,8.898877143859863,5
699,8.759015083312988,6
799,8.768890380859375,7
899,8.79293441772461,8
999,8.733748435974121,9
1099,8.805116653442383,10
1199,8.722960472106934,11
1299,8.698588371276855,12
1399,8.758171081542969,13
1499,8.747028350830078,14
1599,8.72025203704834,15
1699,8.619869232177734,16
1799,8.714813232421875,17
1899,8.77664566040039,18
1999,8.667686462402344,19
2099,8.592418670654297,20
2199,8.665956497192383,21
2299,8.677029609680176,22
2399,8.69179630279541,23
2499,8.719265937805176,24
2599,8.740041732788086,25
2699,8.60983657836914,26
2799,8.672143936157227,27
2899,8.669672012329102,28
2999,8.672944068908691,29
3099,8.600998878479004,30
3199,8.679454803466797,31
3299,8.734262466430664,32
3399,8.623708724975586,33
3499,8.65015983581543,34
3599,8.616643905639648,35
3699,8.648968696594238,36
3799,8.647221565246582,37
3899,8.665446281433105,38
3999,8.661643981933594,39
4099,8.594855308532715,40
4199,8.694247245788574,41
4299,8.649402618408203,42
4399,8.666641235351562,43
4499,8.606537818908691,44
4599,8.631160736083984,45
4699,8.667245864868164,46
4799,8.625722885131836,47
4899,8.680832862854004,48
4999,8.651734352111816,49
