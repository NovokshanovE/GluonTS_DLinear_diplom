step,epoch,train_loss
99,0,22.66861343383789
199,1,8.989593505859375
299,2,8.917487144470215
399,3,8.807616233825684
499,4,8.7639741897583
599,5,8.710770606994629
699,6,8.7268648147583
799,7,8.668423652648926
899,8,8.731904029846191
999,9,8.612168312072754
1099,10,8.691335678100586
1199,11,8.692940711975098
1299,12,8.695596694946289
1399,13,8.634833335876465
1499,14,8.67028522491455
1599,15,8.697493553161621
1699,16,8.65044116973877
1799,17,8.662325859069824
1899,18,8.693355560302734
1999,19,8.644290924072266
2099,20,8.640493392944336
2199,21,8.657154083251953
2299,22,8.651457786560059
2399,23,8.671710014343262
2499,24,8.696281433105469
2599,25,8.678482055664062
2699,26,8.62272834777832
2799,27,8.636863708496094
2899,28,8.6124906539917
2999,29,8.66189956665039
3099,30,8.705353736877441
3199,31,8.662616729736328
3299,32,8.637916564941406
3399,33,8.65293025970459
3499,34,8.664155006408691
3599,35,8.700428009033203
3699,36,8.634346008300781
3799,37,8.655004501342773
3899,38,8.567895889282227
3999,39,8.694425582885742
4099,40,8.683431625366211
4199,41,8.647442817687988
4299,42,8.627098083496094
4399,43,8.638910293579102
4499,44,8.6643648147583
4599,45,8.647989273071289
4699,46,8.611434936523438
4799,47,8.646767616271973
4899,48,8.601021766662598
4999,49,8.606839179992676
