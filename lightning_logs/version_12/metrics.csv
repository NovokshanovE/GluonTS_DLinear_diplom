epoch,step,train_loss
0,99,1490.95654296875
1,199,8.995636940002441
2,299,8.81311321258545
3,399,8.836078643798828
4,499,8.762800216674805
5,599,8.748201370239258
6,699,8.747328758239746
7,799,8.716678619384766
8,899,8.684969902038574
9,999,8.663623809814453
10,1099,8.671281814575195
11,1199,8.632684707641602
12,1299,8.660516738891602
13,1399,8.645469665527344
14,1499,8.659771919250488
15,1599,8.718162536621094
16,1699,8.641257286071777
17,1799,8.647439002990723
18,1899,8.641589164733887
19,1999,8.613537788391113
20,2099,8.562807083129883
21,2199,8.628195762634277
22,2299,8.643543243408203
23,2399,8.594501495361328
24,2499,8.635547637939453
25,2599,8.600497245788574
26,2699,8.631521224975586
27,2799,8.639179229736328
28,2899,8.60545539855957
29,2999,8.639286994934082
30,3099,8.702149391174316
31,3199,8.619270324707031
32,3299,8.587247848510742
33,3399,8.60534954071045
34,3499,8.595382690429688
35,3599,8.638927459716797
36,3699,8.581989288330078
37,3799,8.631207466125488
38,3899,8.583244323730469
39,3999,8.570146560668945
40,4099,8.603137016296387
41,4199,8.651671409606934
42,4299,8.600955963134766
43,4399,8.610998153686523
44,4499,8.643665313720703
45,4599,8.615071296691895
46,4699,8.610647201538086
47,4799,8.618488311767578
48,4899,8.625975608825684
49,4999,8.601016998291016
