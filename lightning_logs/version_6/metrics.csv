step,train_loss,epoch
99,5293.625,0
199,8.943099975585938,1
299,8.772518157958984,2
399,8.802209854125977,3
499,8.697321891784668,4
599,8.640700340270996,5
699,8.670646667480469,6
799,8.658164978027344,7
899,8.54638385772705,8
999,8.656341552734375,9
1099,8.653621673583984,10
1199,8.614226341247559,11
1299,8.59499740600586,12
1399,8.564041137695312,13
1499,8.617480278015137,14
1599,8.663993835449219,15
1699,8.627928733825684,16
1799,8.642660140991211,17
1899,8.596200942993164,18
1999,8.57695198059082,19
2099,8.603409767150879,20
2199,8.605484962463379,21
2299,8.626832008361816,22
2399,8.598825454711914,23
2499,8.58513355255127,24
2599,8.580687522888184,25
2699,8.615143775939941,26
2799,8.581328392028809,27
2899,8.592707633972168,28
2999,8.641529083251953,29
3099,8.568325996398926,30
3199,8.661114692687988,31
3299,8.5617094039917,32
3399,8.553618431091309,33
3499,8.611917495727539,34
3599,8.525012016296387,35
3699,8.59057903289795,36
3799,8.56179141998291,37
3899,8.572189331054688,38
3999,8.525127410888672,39
4099,8.635077476501465,40
4199,8.58419132232666,41
4299,8.618431091308594,42
4399,8.585718154907227,43
4499,8.58574104309082,44
4599,8.538537979125977,45
4699,8.5679292678833,46
4799,8.555335998535156,47
4899,8.60459041595459,48
4999,8.594043731689453,49
