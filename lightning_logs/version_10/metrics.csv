train_loss,epoch,step
919.9659423828125,0,99
8.942610740661621,1,199
8.75468921661377,2,299
8.715246200561523,3,399
8.753596305847168,4,499
8.736473083496094,5,599
8.70732593536377,6,699
8.672625541687012,7,799
8.603643417358398,8,899
8.591972351074219,9,999
8.615033149719238,10,1099
8.623074531555176,11,1199
8.626005172729492,12,1299
8.681595802307129,13,1399
8.632479667663574,14,1499
8.610597610473633,15,1599
8.6312837600708,16,1699
8.610978126525879,17,1799
8.577940940856934,18,1899
8.624770164489746,19,1999
8.575277328491211,20,2099
8.591697692871094,21,2199
8.593276977539062,22,2299
8.600747108459473,23,2399
8.532408714294434,24,2499
8.559810638427734,25,2599
8.551984786987305,26,2699
8.49802017211914,27,2799
8.5463228225708,28,2899
8.569188117980957,29,2999
8.608267784118652,30,3099
8.591408729553223,31,3199
8.554981231689453,32,3299
8.613140106201172,33,3399
8.555524826049805,34,3499
8.555890083312988,35,3599
8.566492080688477,36,3699
8.556775093078613,37,3799
8.55930233001709,38,3899
8.604228973388672,39,3999
8.56242847442627,40,4099
8.59784984588623,41,4199
8.55458927154541,42,4299
8.584281921386719,43,4399
8.538174629211426,44,4499
8.560454368591309,45,4599
8.551721572875977,46,4699
8.554101943969727,47,4799
8.617618560791016,48,4899
8.594295501708984,49,4999
