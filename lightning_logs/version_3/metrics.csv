step,train_loss,epoch
99,10.460868835449219,0
199,9.01032829284668,1
299,8.95186996459961,2
399,8.949440002441406,3
499,8.89211654663086,4
599,8.832108497619629,5
699,8.820137977600098,6
799,8.78012466430664,7
899,8.706147193908691,8
999,8.75451946258545,9
1099,8.658589363098145,10
1199,8.715005874633789,11
1299,8.668277740478516,12
1399,8.650533676147461,13
1499,8.659370422363281,14
1599,8.649575233459473,15
1699,8.636775016784668,16
1799,8.689093589782715,17
1899,8.692519187927246,18
1999,8.618660926818848,19
2099,8.571846961975098,20
2199,8.686656951904297,21
2299,8.663727760314941,22
2399,8.615309715270996,23
2499,8.576983451843262,24
2599,8.61350154876709,25
2699,8.6248197555542,26
2799,8.635104179382324,27
2899,8.553567886352539,28
2999,8.582071304321289,29
3099,8.592700958251953,30
3199,8.65235710144043,31
3299,8.576991081237793,32
3399,8.661663055419922,33
3499,8.644164085388184,34
3599,8.676982879638672,35
3699,8.611791610717773,36
3799,8.654802322387695,37
3899,8.625007629394531,38
3999,8.630942344665527,39
4099,8.68932819366455,40
4199,8.646458625793457,41
4299,8.638657569885254,42
4399,8.614124298095703,43
4499,8.607491493225098,44
4599,8.658287048339844,45
4699,8.597349166870117,46
4799,8.712983131408691,47
4899,8.683255195617676,48
4999,8.575390815734863,49
