epoch,train_loss,step
0,810.957763671875,99
1,9.25146484375,199
2,9.093487739562988,299
3,8.996539115905762,399
4,8.933908462524414,499
5,8.739755630493164,599
6,8.693316459655762,699
7,8.719058990478516,799
8,8.712905883789062,899
9,8.621358871459961,999
10,8.706501007080078,1099
11,8.64034652709961,1199
12,8.665213584899902,1299
13,8.599006652832031,1399
14,8.614278793334961,1499
15,8.620244979858398,1599
16,8.636497497558594,1699
17,8.598306655883789,1799
18,8.665033340454102,1899
19,8.631726264953613,1999
20,8.557843208312988,2099
21,8.6380033493042,2199
22,8.590658187866211,2299
23,8.573956489562988,2399
24,8.582733154296875,2499
25,8.623368263244629,2599
26,8.614243507385254,2699
27,8.549467086791992,2799
28,8.591750144958496,2899
29,8.60971450805664,2999
30,8.541924476623535,3099
31,8.649261474609375,3199
32,8.591580390930176,3299
33,8.611886024475098,3399
34,8.61866569519043,3499
35,8.558335304260254,3599
36,8.648152351379395,3699
37,8.570425033569336,3799
38,8.591261863708496,3899
39,8.589771270751953,3999
40,8.581989288330078,4099
41,8.632462501525879,4199
42,8.612279891967773,4299
43,8.574418067932129,4399
44,8.615209579467773,4499
45,8.572489738464355,4599
46,8.564839363098145,4699
47,8.586185455322266,4799
48,8.613903045654297,4899
49,8.613633155822754,4999
